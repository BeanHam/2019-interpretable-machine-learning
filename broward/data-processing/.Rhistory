people_df<-tbl(db,"people") %>%
as_data_frame() %>%
mutate(dob = as_date(ymd_hms(dob))) %>%
rename(person_id = id)
## Cleanup
rm(db)
gc()
#charge_df %>% filter(charge_degree == "(TCX)") %>% count(statute)
#nrow(charge_df) #this is charge_df without all the "0" charge_degrees, minor offenses
### Load our data
#fail_to_appear <- read_csv(paste0(f_our_data,"fail_to_appear.csv"))
#convictions <- read_csv(paste0(f_our_data,"convicted_from_disps.csv"))
eventsdescrp_df<-read_csv(paste0(f_our_data,"eventsdescrp_df1.csv"))%>%
bind_rows(.,read_csv(paste0(f_our_data,"eventsdescrp_df2.csv"))) %>%
bind_rows(.,read_csv(paste0(f_our_data,"eventsdescrp_df3.csv"))) %>%
bind_rows(.,read_csv(paste0(f_our_data,"eventsdescrp_df4.csv")))
### Probation features
event_on = c("File Order Of Probation")
event_off = c("File Order Of Revocation Of Probation",
"File Expiration Of Probation",
"File Order Granting Def Motion To Terminate Probation",
"File Order Of Termination Of Probation")
event_revoke = c("File Order Of Revocation Of Probation")
prob_df = eventsdescrp_df %>%
mutate(prob_event0 = if_else(Description %in% event_on, "On",
if_else(Description %in% event_off, "Off", as.character(NA)))) %>%
filter(!is.na(prob_event0)) %>%
mutate(EventDate = mdy(EventDate))
## How often do both "On" and "Off" occur on the same day?
prob_df %>%
group_by(person_id, EventDate) %>%
summarize(n_on = sum(prob_event0 =="On"), n_off = sum(prob_event0=="Off")) %>%
mutate(both = n_on>0 & n_off>0) %>%
filter(both)
## Now assign single "On"/"Off" to each day. If any event is "On" then label day as "On"
prob_df = prob_df %>%
group_by(person_id, EventDate) %>%
summarize(
prob_event = if_else(any(prob_event0 == "On"), "On", "Off"),
is_revoke = if_else(prob_event == "Off" & any(Description %in% event_revoke), 1, 0)
) %>%
arrange(person_id, EventDate) # This is important
# Check how many duplicates there are
compas_df %>%
group_by(person_id, screening_date) %>%
summarize(duplicate = n() > 3) %>%
group_by(duplicate) %>%
summarize(count = n())
# Remove duplicates
compas_df2 = compas_df %>%
group_by(person_id, screening_date) %>%
arrange(desc(compas_case_id)) %>%
dplyr::slice(1:3) # Should be three scores for each compas_case_id
# Convert compas scores to wide format (one row per person_id/screening_date combination)
compas_df_wide = compas_df2 %>%
select(person_id, screening_date, type_of_assessment, raw_score, decile_score) %>%
gather("key","value",raw_score,decile_score) %>%
unite(temp, type_of_assessment, key) %>%
spread(temp, value) %>%
ungroup()
# Compute the date of the first offense
key_first_offense = compas_df_wide %>%
left_join(charge_df, by="person_id") %>% # Duplicate charges for each screening_date
group_by(person_id, screening_date) %>%
summarize(first_offense_date = min(offense_date))
# Compute the date of the current offense
key_current_offense = compas_df_wide %>%
left_join(charge_df, by="person_id") %>% # Duplicate charges for each screening_date
mutate(days_offense_screening = floor(as.numeric(as.period(interval(offense_date,screening_date)), "days"))) %>%
filter(days_offense_screening >= 0 & days_offense_screening <= 30) %>%
group_by(person_id, screening_date) %>%
summarize(current_offense_date = max(offense_date))
# Compute last current offense date allowed (two years before when data pulled)
#current_offense_date_limit = max(charge_df$offense_date) - years(2)
current_offense_date_limit = max(charge_df$offense_date, na.rm = T) - years(2)
# Record important dates
key_events = compas_df_wide %>%
select(person_id, screening_date) %>%
left_join(key_first_offense, by = c("person_id","screening_date")) %>%
left_join(key_current_offense, by = c("person_id","screening_date"))
### Add columns to ProPublica tables. Each entry should depend only on other entries in the same row.
charge_df = charge_df %>%
left_join(select(people_df, person_id, dob),by="person_id") %>% # Add date of birth
filter(!is.na(statute)) %>%
mutate(
is_violent=if_else(substr(statute,1,3) %in% c("741","777","782","784","794",
"806","812","825","827"),1,0),
is_felony = if_else(substr(charge_degree,2,2)=="F",1,0),
is_misdem= if_else(substr(charge_degree,2,2)=="M",1,0),
is_property=if_else(substr(statute,1,3) %in% c("806","810","812"),1,0),
is_murder=if_else(substr(statute,1,3) %in% c("782"),1,0),
is_assault=if_else(substr(statute,1,3) %in% c("784"),1,0),
is_family_violence=if_else(substr(statute,1,6)=="741.28",1,0),
is_sex_offense=if_else(substr(statute,1,3)=="794"|
substr(statute,1,7)=="784.046",1,0),
is_weapons=if_else(substr(statute,1,3)=="790",1,0),
is_felprop_violarrest=if_else(is_violent==1&is_felony==1&is_property==1,1,0),
is_felassault_arrest=if_else(is_felony==1&is_assault==1,1,0),
is_misdemassault_arrest=if_else(is_misdem==1&is_assault==1,1,0),
age_offense = floor(as.numeric(as.period(interval(dob,offense_date)), "years")),
is_juv = age_offense < 18,
#additional features calculated for psa_analysis
is_traffic = if_else(substr(charge_degree, 0, 5) %in% c("(TCX)"), 1, 0),
is_drug = if_else(substr(statute,1,3) == "893" |
substr(statute,1,7) %in% c("817.563","817.546"),1,0),
is_dui = if_else(substr(statute,1,7) %in% c("316.193","322.056") |
substr(statute,1,6) %in% c("322.62","322.63","322.64"),1,0),
is_domestic_viol = if_else(substr(statute,1,6) %in% c("741.29", "741.28","741.30", "741.32"),1,0),
#keywords of stalking, harassment,
is_stalking = if_else(substr(statute,1,7) %in% c("784.048", "784.049"),1,0),
is_voyeurism = if_else(charge == "Voyeurism" | substr(statute,1,6) %in% c("810.14") | substr(statute,1,7) %in% c("827.071")
| substr(statute,1,3) %in% c("847"),1,0),
is_fraud = if_else(substr(statute,1,3) %in% c("817"),1,0) ,
#includes theft robbery and burglary
is_stealing = if_else(substr(statute,1,3) %in% c("812")|substr(statute,1,6) %in% c("810.06","810.02") ,1,0) ,
#burglary trespass and voyeurism #Bhrij: I will switch the voyeurism to itself
is_trespass = if_else(substr(statute,1,3) %in% c("810"),1,0)
)%>%
select(-dob)
charge_df %>% select(-id, -filing_date, -offense_date, -charge_number, -charge_degree, -date_charge_filed, -filing_type, -filing_agency, -name, -days_since_compas, -person_id)
jailhistory_df = jailhistory_df %>%
mutate(sentence_days = floor(as.numeric(as.period(interval(in_custody,out_custody)), "days")))
prisonhistory_df = prisonhistory_df %>%
mutate(sentence_days = floor(as.numeric(as.period(interval(in_custody,out_custody)), "days")))
dyn_arrest = key_events %>%
left_join(casearrest_df, by="person_id") %>% # Duplicates features for different screening_dates
filter(arrest_date < current_offense_date) %>% # Only charges before the current offense should matter
select(-first_offense_date, -current_offense_date) %>% # Don't need these here now
group_by(person_id, screening_date) %>%
nest(.key="arrest")
dyn_charge = key_events %>%
left_join(charge_df, by="person_id") %>%
filter(offense_date < current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="charge")
dyn_jail = key_events %>%
left_join(jailhistory_df, by="person_id") %>%
filter(in_custody < current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="jail")
dyn_prison = key_events %>%
left_join(prisonhistory_df, by="person_id") %>%
filter(in_custody < current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prison")
dyn_prob = key_events %>%
left_join(prob_df, by="person_id") %>%
#filter(EventDate < current_offense_date) %>% # Don't filter out probation events past screening_date since probation ending after screening_date may be useful to know ?
filter(!(is.na(EventDate))) %>% # Need this if no date filtering
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prob")
stat_people = key_events %>%
left_join(people_df, by="person_id") %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="people")
### Join all information together. Each row is a unique person_id/screening_date.
data_before = key_events %>%
left_join(dyn_arrest, by=c("person_id","screening_date")) %>%
left_join(dyn_charge, by=c("person_id","screening_date")) %>%
left_join(dyn_jail, by=c("person_id","screening_date")) %>%
left_join(dyn_prison, by=c("person_id","screening_date")) %>%
left_join(dyn_prob, by=c("person_id","screening_date")) %>%
inner_join(stat_people, by=c("person_id","screening_date")) # Should be 1-1 mapping between dataframes
### Compute features (e.g., number of priors) for each person_id/screening_date combination.
features = pmap_dfr(data_before, .f=compute_features)
year_feature = pmap_dfr(data_before, .f=compute_past_crimes)
### Join with COMPAS scores=
features = key_events %>%
inner_join(features, by=c("person_id","screening_date")) %>%
inner_join(compas_df_wide, by=c("person_id","screening_date")) %>%
inner_join(year_feature, by=c("person_id", "screening_date"))
dyn_arrest = key_events %>%
left_join(casearrest_df, by="person_id") %>% # Duplicates features for different screening_dates
filter(arrest_date <= current_offense_date) %>% # Only charges before the current offense should matter
select(-first_offense_date, -current_offense_date) %>% # Don't need these here now
group_by(person_id, screening_date) %>%
nest(.key="arrest")
dyn_charge = key_events %>%
left_join(charge_df, by="person_id") %>%
filter(offense_date <= current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="charge")
dyn_jail = key_events %>%
left_join(jailhistory_df, by="person_id") %>%
filter(in_custody <= current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="jail")
dyn_prison = key_events %>%
left_join(prisonhistory_df, by="person_id") %>%
filter(in_custody <= current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prison")
dyn_prob = key_events %>%
left_join(prob_df, by="person_id") %>%
#filter(EventDate < current_offense_date) %>% # Don't filter out probation events past screening_date since probation ending after screening_date may be useful to know
filter(!(is.na(EventDate))) %>% # Need this if no date filtering
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prob")
stat_people = key_events %>%
left_join(people_df, by="person_id") %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="people")
### Join all information together. Each row is a unique person_id/screening_date.
data_before_on = key_events %>%
left_join(dyn_arrest, by=c("person_id","screening_date")) %>%
left_join(dyn_charge, by=c("person_id","screening_date")) %>%
left_join(dyn_jail, by=c("person_id","screening_date")) %>%
left_join(dyn_prison, by=c("person_id","screening_date")) %>%
left_join(dyn_prob, by=c("person_id","screening_date")) %>%
inner_join(stat_people, by=c("person_id","screening_date")) # Should be 1-1 mapping between dataframes
### Compute features (e.g., number of priors) for each person_id/screening_date combination.
features_before_on = pmap_dfr(data_before_on, .f=compute_features)
### Join with COMPAS scores=
features_before_on = key_events %>%
inner_join(features_before_on, by=c("person_id","screening_date")) %>%
inner_join(compas_df_wide, by=c("person_id","screening_date"))
dyn_arrest_on = key_events %>%
left_join(casearrest_df, by="person_id") %>% # Duplicates features for different screening_dates
filter(arrest_date == current_offense_date) %>% # Only charges before the current offense should matter
select(-first_offense_date, -current_offense_date) %>% # Don't need these here now
group_by(person_id, screening_date) %>%
nest(.key="arrest")
dyn_charge_on = key_events %>%
left_join(charge_df, by="person_id") %>%
filter(offense_date == current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="charge")
dyn_jail_on = key_events %>%
left_join(jailhistory_df, by="person_id") %>%
filter(in_custody == current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="jail")
dyn_prison_on = key_events %>%
left_join(prisonhistory_df, by="person_id") %>%
filter(in_custody == current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prison")
dyn_prob_on = key_events %>%
left_join(prob_df, by = "person_id") %>%
filter(EventDate == current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prob")
### Join all information together. Each row is a unique person_id/screening_date.
data_on = key_events %>%
left_join(dyn_arrest_on, by=c("person_id","screening_date")) %>%
left_join(dyn_charge_on, by=c("person_id","screening_date")) %>%
left_join(dyn_jail_on, by=c("person_id","screening_date")) %>%
left_join(dyn_prison_on, by=c("person_id","screening_date")) %>%
left_join(dyn_prob_on, by=c("person_id","screening_date"))
features_on = pmap_dfr(data_on, .f=compute_features_on)
dyn_arrest_after = key_events %>%
left_join(casearrest_df, by="person_id") %>% # Duplicates features for different screening_dates
filter(arrest_date > current_offense_date) %>% # Only charges before the current offense should matter
select(-first_offense_date, -current_offense_date) %>% # Don't need these here now
group_by(person_id, screening_date) %>%
nest(.key="arrest")
dyn_charge_after = key_events %>%
left_join(charge_df, by="person_id") %>%
filter(offense_date > current_offense_date) %>% #
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="charge")
dyn_jail_after = key_events %>%
left_join(jailhistory_df, by="person_id") %>%
filter(in_custody > current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="jail")
dyn_prison_after = key_events %>%
left_join(prisonhistory_df, by="person_id") %>%
filter(in_custody > current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prison")
dyn_prob_after = key_events %>%
left_join(prob_df, by="person_id") %>%
filter(EventDate > current_offense_date) %>%
select(-first_offense_date, -current_offense_date) %>%
group_by(person_id, screening_date) %>%
nest(.key="prob")
### Join all information together. Each row is a unique person_id/screening_date.
data_after = key_events %>%
left_join(dyn_arrest_after, by=c("person_id","screening_date")) %>%
left_join(dyn_charge_after, by=c("person_id","screening_date")) %>%
left_join(dyn_jail_after, by=c("person_id","screening_date")) %>%
left_join(dyn_prison_after, by=c("person_id","screening_date")) %>%
left_join(dyn_prob_after, by=c("person_id","screening_date"))
nrow(data_after)
outcomes = pmap_dfr(data_after, .f=compute_outcomes)
options(tibble.print_max = 20, tibble.print_min = 100)
options(tibble.width = Inf)
nrow(outcomes)
outcomes
bad_values <- outcomes %>%
filter(is.na(years))
#bad_values
new <- outcomes %>%
na.exclude()
new %>% select(general_two_year, recidnot, years)
overall_amt = sum(new$general_two_year, na.rm = TRUE)
outcomes$general_two_year[1:10]
nrow(new)
not_overall_amt = sum(new$recidnot, na.rm = TRUE)
outcomes$recidnot[1:10]
print("Screening dates\n")
outcomes$screening_date[1:10]
#outcomes$date[1:10]
print("Years inbetween")
outcomes$years[1:10]
drug_amt = sum(new$recid_drug, na.rm = TRUE)
property_amt = sum(new$recid_property, na.rm = TRUE)
stalking_amt = sum(new$recid_stalking, na.rm = TRUE)
dom_amt = sum(new$recid_domestic, na.rm = TRUE)
trespass_amt = sum(new$recid_trespass, na.rm = TRUE)
traffic_amt = sum(new$recid_traffic, na.rm = TRUE)
voy_amt = sum(new$recid_voyeurism, na.rm = TRUE)
fraud_amt = sum(new$recid_fraud, na.rm = TRUE)
steal_amt = sum(new$recid_stealing, na.rm = TRUE)
dui_amt = sum(new$recid_dui, na.rm = TRUE)
murder_amt = sum(new$recid_murder, na.rm = TRUE)
voverall_amt = sum(outcomes$recid_violent, na.rm = TRUE)
vproperty_amt = sum(outcomes$recid_property_violent, na.rm = TRUE)
vstalking_amt = sum(outcomes$recid_stalking_violent, na.rm = TRUE)
vdom_amt = sum(outcomes$recid_domestic_violent, na.rm = TRUE)
vtrespass_amt = sum(outcomes$recid_trespass_violent, na.rm = TRUE)
vtraffic_amt = sum(outcomes$recid_traffic_violent, na.rm = TRUE)
vvoy_amt = sum(outcomes$recid_voyeurism_violent, na.rm = TRUE)
vfraud_amt = sum(outcomes$recid_fraud_violent, na.rm = TRUE)
vsteal_amt = sum(outcomes$recid_stealing_violent, na.rm = TRUE)
vdui_amt = sum(outcomes$recid_dui_violent, na.rm = TRUE)
vdrug_amt = sum(outcomes$recid_drug_violent, na.rm = TRUE)
vmurder_amt = sum(outcomes$recid_murder_violent, na.rm = TRUE)
crimes <- c("Not","Overall", "Drug", "Property", "Stalking", "Domestic Violence", "Trespass", "Traffic", "Voyeurism", "Fraud", "Stealing", "DUI", "Murder")
amt <- c(not_overall_amt, overall_amt, drug_amt, property_amt, stalking_amt, dom_amt, trespass_amt, traffic_amt, voy_amt, fraud_amt, steal_amt, dui_amt, murder_amt)
vamt <- c(not_overall_amt, voverall_amt, vdrug_amt, vproperty_amt, vstalking_amt, vdom_amt, vtrespass_amt, vtraffic_amt, vvoy_amt, vfraud_amt, vsteal_amt, vdui_amt, vmurder_amt)
out_graph = data.frame(Crime = crimes, Frequency = amt, Frequency_Violent = vamt)
out_graph
ggplot(data = out_graph, mapping = aes(x = Crime, y = Frequency)) +
geom_col() + labs(title = "Crime Recidivised", x = "Crime", y = "Frequency") + coord_flip()
ggplot(data = out_graph, mapping = aes(x = Crime, y = Frequency_Violent)) +
geom_col() + labs(title = "Crime Recidivised", x = "Crime", y = "Frequency") + coord_flip()
#out_graph = pmap_dfr(data_after, .f=compute_outcomes_graph)
#out_graph
#ggplot(data = out_graph, mapping = aes(x = crime)) +
#  geom_bar() + labs(title = "Crimed Committed", x = "Crime", y = "Frequency")
save(data_before, data_on, data_after, data_before_on,
features, features_before_on, features_on, outcomes,
compas_df_wide,
current_offense_date_limit,
file = "expanded_features.Rdata")
write.csv(outcomes, file = "labels.csv", row.names = FALSE)
knitr::opts_chunk$set(warning=F, message=F,echo = TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
library(tidyverse)
library(magrittr)
require(caret)
data_path = "C:/Users/binha/Documents/Duke/Cynthia Research/interpretable-machine-learning/broward/data-processing/"
load(paste0(data_path, "compas_psa.Rdata"))
load(paste0(data_path, "expanded_features.Rdata"))
labels = read_csv(paste0(data_path, "labels.csv")) %>%
mutate(screening_date = as.Date(screening_date, format = "%m/%d/%Y"))
### Add useful columns to features and apply row filters used for all models
features_filt = features_before_on %>%
select(-p_incarceration) %>%
inner_join(
data_before %>%
select(person_id, screening_date, people) %>%
unnest() %>%
select(person_id, screening_date, race, sex, name),
by = c("person_id","screening_date")
) %>%
mutate(sex = ifelse(sex == "Male", 1, 0)) %>% #change sex variable to numeric encoding
inner_join(features_on, by = c("person_id","screening_date")) %>%
inner_join(
psa_features%>%
select(-c(p_current_age, p_prison)),
by = c("person_id","screening_date")) %>%
inner_join(outcomes, by = c("person_id","screening_date")) %>%
inner_join(
features %>%
select(person_id, screening_date, p_incarceration, years_since_last_crime, six_month,
one_year, three_year, five_year),
by = c("person_id", "screening_date")) %>%
filter(`Risk of Recidivism_decile_score` != -1, `Risk of Violence_decile_score` != -1) %>% # Filter 1
filter(!is.na(current_offense_date)) %>% # Filter 3
filter(screening_date <= current_offense_date_limit) %>% # Filter 4
mutate(decile_use = `Risk of Recidivism_decile_score`) # Select recidivism or violent recidivism decile score to use in this script
###########################################################
## PSA available set
df_psa = features_filt %>%
transmute(
person_id,
sex,
race,
screening_date,
#COMPAS Risk of Recidivism Features\
age_at_current_charge,
age_at_first_charge,
p_charges,
p_incarceration = p_incarceration,
p_probation = p_probation,
#COMPAS Risk of violent recidivism features
p_juv_fel_count,
p_felprop_viol,
p_murder,
p_felassault,
p_misdeassault,
p_famviol,
p_sex_offense,
p_weapon,
#PSA Features (which were not named above)
fail_appear_two_yr,
fail_appear_two_plus,
current_violent,
current_violent20,
pending_charge,
prior_conviction_F,
prior_conviction_M,
violent_conviction,
total_convictions,
#Misc Features
p_arrest,
p_property,
p_traffic,
p_drug,
p_dui,
p_domestic,
p_stalking,
p_voyeurism,
p_fraud,
p_stealing,
p_trespass,
six_month,
one_year,
three_year,
five_year) %>%
rename(p_fta_two_year = fail_appear_two_yr,
p_fta_two_year_plus = fail_appear_two_plus,
current_violence = current_violent,
current_violence20 = current_violent20,
p_pending_charge = pending_charge,
p_felony = prior_conviction_F,
p_misdemeanor = prior_conviction_M,
p_violence = violent_conviction) %>%
na.omit()
colnames(labels)
## merge df with labels
df_psa = merge(x=df_psa, y =labels, by=c('person_id', 'screening_date'))%>%
select(person_id:general_six_month,
drug_two_year,
property_two_year,
misdemeanor_two_year,
felony_two_year,
violent_two_year,
drug_six_month,
property_six_month,
misdemeanor_six_month,
felony_six_month,
violent_six_month) %>%
mutate(general_two_year = as.factor(general_two_year),
drug_two_year = as.factor(drug_two_year),
property_two_year = as.factor(property_two_year),
felony_two_year = as.factor(felony_two_year),
misdemeanor_two_year = as.factor(misdemeanor_two_year),
violent_two_year = as.factor(violent_two_year),
general_six_month = as.factor(general_six_month),
drug_six_month = as.factor(drug_six_month),
property_six_month = as.factor(property_six_month),
felony_six_month = as.factor(felony_six_month),
misdemeanor_six_month = as.factor(misdemeanor_six_month),
violent_six_month = as.factor(violent_six_month))
## compass & arnold
scores_outcomes = compas_psa_wide %>%
filter(`Risk of Violence_decile_score`>=0,
`Risk of Recidivism_decile_score`>=0,
`Risk of Failure to Appear_decile_score`>=0) %>%
left_join(outcomes, by=c("person_id","screening_date")) %>%
merge(x=., y=df_psa %>% select(person_id, screening_date, sex, race,
age_at_current_charge, p_charges),
by = c("person_id", "screening_date"))
### split train and test for those models with 5-general-CV
set.seed(816)
psa_test_sample = sample(1:nrow(df_psa), 0.2*nrow(df_psa), replace = FALSE)
psa_test = df_psa[psa_test_sample,]
psa_train = df_psa[-psa_test_sample, ]
arnold_test = scores_outcomes[psa_test_sample, ]
arnold_train = scores_outcomes[-psa_test_sample, ]
saving_path = "C:/Users/binha/Documents/Duke/Cynthia Research/interpretable-machine-learning/broward/data/"
## psa subset
write.csv(df_psa, file = paste0(saving_path, "broward_data.csv"), row.names = F)
write.csv(psa_train, file = paste0(saving_path, "broward_train.csv"), row.names = F)
write.csv(psa_test, file = paste0(saving_path, "broward_test.csv"), row.names = F)
## psa scores
write.csv(scores_outcomes, file = paste0(saving_path, "broward_arnold.csv"), row.names = F)
write.csv(arnold_train, file = paste0(saving_path, "broward_arnold_train.csv"), row.names = F)
write.csv(arnold_test, file = paste0(saving_path, "broward_arnold_test.csv"), row.names = F)
## index
write.csv(psa_test_sample, file = paste0(saving_path, "broward_test_index.csv"), row.names = F)
