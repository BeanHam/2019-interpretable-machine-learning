{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.interpretable_functions as interpret\n",
    "import utils.RiskSLIM as slim\n",
    "import utils.stumps as stumps\n",
    "import utils.fairness_functions as fairness\n",
    "import utils.risktool as risktool\n",
    "from utils.load_settings import load_settings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pprint import pprint\n",
    "from riskslim.helper_functions import load_data_from_csv, print_model\n",
    "\n",
    "# restore saved variables\n",
    "# %store -r summary_property6_FL_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CART & EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./broward/data/broward_data.csv\").sort_values('person_id')\n",
    "x = data.loc[:,:'five_year']\n",
    "y = data['property_six_month'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CART\n",
    "depth = [1,2,3,4,5]\n",
    "impurity = [0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "cart_summary = interpret.CART(X=x,\n",
    "                              Y=y,\n",
    "                              depth=depth,\n",
    "                              impurity=impurity, \n",
    "                              seed = 816)\n",
    "\n",
    "#### EBM\n",
    "estimators = [40,60,80,100]\n",
    "depth = [1,2,3]\n",
    "learning_rate = [0.01]\n",
    "holdout_split = [0.7, 0.9]\n",
    "ebm_summary = interpret.EBM(X=x,\n",
    "                       Y=y,\n",
    "                       learning_rate = learning_rate,\n",
    "                       depth = depth,\n",
    "                       estimators=estimators,\n",
    "                       holdout_split=holdout_split,\n",
    "                       seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CART: \", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs']))\n",
    "print(\"EMB: \", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lasso Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stumps & original data\n",
    "data = pd.read_csv(\"./broward/data/broward_stumps.csv\").sort_values('person_id')\n",
    "original_data = pd.read_csv(\"./broward/data/broward_data.csv\").sort_values('person_id')\n",
    "original_data = original_data.loc[:, ['person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "data = pd.merge(original_data, data, on=['person_id', 'screening_date'])\n",
    "\n",
    "## split X & Y\n",
    "X_stumps = data.loc[:,:'five_year1'].copy()\n",
    "Y_stumps = data['property_six_month'].values.copy()\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[5:]\n",
    "\n",
    "## load train & test stumps data\n",
    "train_stumps = pd.read_csv(\"./broward/data/broward_train_stumps.csv\").sort_values('person_id')\n",
    "test_stumps = pd.read_csv(\"./broward/data/broward_test_stumps.csv\").sort_values('person_id')\n",
    "X_train_stumps = train_stumps.loc[:,:'five_year1'].copy()\n",
    "X_test_stumps = test_stumps.loc[:,:'five_year1'].copy()\n",
    "Y_train_stumps = train_stumps['property_six_month'].values.copy()\n",
    "Y_test_stumps = test_stumps['property_six_month'].values.copy()\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                        Y_train_stumps, \n",
    "                                        X_test_stumps, \n",
    "                                        Y_test_stumps, \n",
    "                                        c=0.06, \n",
    "                                        columns=cols, \n",
    "                                        seed=816)\n",
    "## unique original features\n",
    "unique_stumps = []\n",
    "for i in single_stump_model['features']:\n",
    "    unique_stumps.append(''.join([j for j in i if not j.isdigit()]))\n",
    "print(len(np.unique(unique_stumps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CART: \", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs']))\n",
    "print(\"EMB: \", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs']))\n",
    "print(\"Additive:\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RiskSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stumps data\n",
    "data = pd.read_csv(\"./broward/data/broward_stumps.csv\").sort_values('person_id')\n",
    "\n",
    "single_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                      Y_train_stumps, \n",
    "                                      X_test_stumps, \n",
    "                                      Y_test_stumps,  \n",
    "                                      c=0.04, \n",
    "                                      columns=cols, \n",
    "                                      seed=816)\n",
    "len(single_stump_model['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset features\n",
    "selected_features = single_stump_model['features']\n",
    "if 'sex1' in selected_features:\n",
    "    selected_features = ['property_six_month', 'person_id', 'screening_date', 'race'] + selected_features\n",
    "    indicator = 1\n",
    "else:\n",
    "    selected_features = ['property_six_month', 'person_id', 'screening_date', 'race', 'sex1'] + selected_features\n",
    "    indicator = 0\n",
    "    \n",
    "sub_data = data[selected_features]\n",
    "sub_data = pd.merge(sub_data, original_data, on=['person_id', 'screening_date'])\n",
    "sub_X, sub_Y = sub_data.iloc[:,1:], sub_data.iloc[:,0].values\n",
    "sub_X.insert(0, '(Intercept)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskslim_cs_summary = slim.risk_nested_cv_constrain(X=sub_X, \n",
    "                                                    Y=sub_Y, \n",
    "                                                    indicator = indicator,\n",
    "                                                    y_label='property_six_month',\n",
    "                                                    max_coef=5,  \n",
    "                                                    max_coef_number=10, \n",
    "                                                    max_runtime=1000, \n",
    "                                                    max_offset=100,\n",
    "                                                    c=1e-3, \n",
    "                                                    seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs']))\n",
    "print(np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs']))\n",
    "print(np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs']))\n",
    "print(np.mean(riskslim_summary['test_auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Single RiskSLIM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"property_six_month\"] + single_stump_model['features']\n",
    "sub_train_data = train_stumps[selected_features]\n",
    "sub_test_data = test_stumps[selected_features]\n",
    "\n",
    "## split x \n",
    "sub_train_X = sub_train_data.iloc[:,1:]\n",
    "sub_train_X.insert(0, '(Intercept)', 1)\n",
    "sub_cols = sub_train_X.columns.tolist()\n",
    "sub_train_X = sub_train_X.values\n",
    "sub_test_X = sub_test_data.iloc[:,1:].values\n",
    "\n",
    "## split y\n",
    "sub_train_Y = sub_train_data.iloc[:,0].values.reshape(-1,1)\n",
    "sub_test_Y = sub_test_data.iloc[:,0].values.reshape(-1,1)\n",
    "\n",
    "## sample weight\n",
    "sample_weights = np.repeat(1, len(sub_train_Y))\n",
    "\n",
    "## new_train_data\n",
    "new_train_data = {\n",
    "    'X': sub_train_X,\n",
    "    'Y': sub_train_Y,\n",
    "    'variable_names': sub_cols,\n",
    "    'outcome_name': 'property_six_month',\n",
    "    'sample_weights': sample_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info, mip_info, lcpa_info = slim.risk_slim_constrain(new_train_data, \n",
    "                                                           max_coefficient=5, \n",
    "                                                           max_L0_value=10, \n",
    "                                                           c0_value=1e-3, \n",
    "                                                           max_offset=100, \n",
    "                                                           max_runtime=1000)\n",
    "print_model(model_info['solution'], new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_X = sub_train_X[:,1:]\n",
    "sub_train_Y[sub_train_Y == -1] = 0\n",
    "sub_test_Y[sub_test_Y == -1] = 0\n",
    "\n",
    "print(\"Train AUC: {}\".format(roc_auc_score(sub_train_Y, slim.riskslim_prediction(sub_train_X, np.array(cols), model_info).reshape(-1,1))))\n",
    "print(\"Test AUC: {}\".format(roc_auc_score(sub_test_Y, slim.riskslim_prediction(sub_test_X, np.array(cols), model_info).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"./broward/data/broward_arnold.csv\").sort_values('person_id')\n",
    "X_arnold = data.loc[:,['arnold_nca', 'sex', 'race', 'person_id', \n",
    "                       'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "Y_arnold = data['property_six_month'].values\n",
    "\n",
    "## test model\n",
    "arnold = risktool.risktool(X_arnold, Y_arnold, label='arnold_nca')\n",
    "print(np.mean(arnold['auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Single Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./broward/data/broward_arnold_test.csv\")\n",
    "X = test_data['arnold_nca'].values\n",
    "Y = test_data['property_six_month'].values\n",
    "roc_auc_score(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"./broward/data/broward_arnold.csv\").sort_values('person_id')\n",
    "X_arnold = data.loc[:,['Risk of Recidivism_decile_score', 'sex', 'race', 'person_id', \n",
    "                       'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "Y_arnold = data['property_six_month'].values\n",
    "\n",
    "## test model\n",
    "compas = risktool.risktool(X_arnold, Y_arnold, label='Risk of Recidivism_decile_score')\n",
    "print(np.mean(compas['auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save results\n",
    "summary_property6_FL_interpret = {\"cart\": cart_summary,\n",
    "                                  \"ebm\": ebm_summary, \n",
    "                                  'stumps': stump_summary, \n",
    "                                  'riskslim': riskslim_cs_summary, \n",
    "                                  'arnold': arnold, \n",
    "                                  'compas': compas}\n",
    "# %store summary_property6_FL_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[\"cart\", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])],\n",
    "           [\"ebm\", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])], \n",
    "           [\"stumps\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])],\n",
    "           ['riskslim', np.mean(riskslim_cs_summary['test_auc'])],\n",
    "           ['arnold', np.mean(arnold['auc'])], \n",
    "           ['compas', np.mean(compas['auc'])]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = [np.mean(cart_summary['holdout_test_auc']), \n",
    "       np.mean(ebm_summary['holdout_test_auc']), \n",
    "       np.mean(stump_summary['holdout_test_auc']), \n",
    "       np.mean(riskslim_cs_summary['test_auc']),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./broward/logs/interpretable/\"\n",
    "results = [[\"Property\", np.str((round(np.mean(cart_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(cart_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(ebm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(ebm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(stump_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(stump_summary['holdout_test_auc']), 3)) + \")\",             \n",
    "            np.str(round(np.mean(riskslim_cs_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(riskslim_cs_summary['test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3),\n",
    "            np.str(round(np.mean(arnold['auc']), 3)) + \" (\" + np.str(round(np.std(arnold['auc']),3)) + \")\", \n",
    "            np.str(round(np.mean(compas['auc']), 3)) + \" (\" + np.str(round(np.std(compas['auc']),3)) + \")\"]]\n",
    "with open(path + 'FL-six-month-interpretable-summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Fairness Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = ['confusion_matrix_stats', 'calibration_stats', 'race_auc', 'condition_pn', 'no_condition_pn']\n",
    "name = ['confusion', 'calibration', 'race-auc', 'condition-pn', 'no-condition-pn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matrix)):\n",
    "    \n",
    "    if ( (i == 0) | (i == 1) ):\n",
    "        \n",
    "        path = './broward/fairness/' + name[i] + '/six-month/property/'\n",
    "        ## confusion matrix and calibration only applies to cart, ebm, riskslim and stumps\n",
    "        cart_matrix = cart_summary[matrix[i]]\n",
    "        ebm_matrix = ebm_summary[matrix[i]]\n",
    "        riskslim_matrix = riskslim_cs_summary[matrix[i]]\n",
    "        stumps_matrix = stump_summary[matrix[i]]\n",
    "        \n",
    "        ## save results\n",
    "        cart_matrix.to_csv(path+'cart-'+name[i]+'.csv', index=None,header=True)\n",
    "        ebm_matrix.to_csv(path+'ebm-'+name[i]+'.csv', index=None,header=True)\n",
    "        riskslim_matrix.to_csv(path+'riskslim-'+name[i]+'.csv', index=None,header=True)\n",
    "        stumps_matrix.to_csv(path+'stumps-'+name[i]+'.csv', index=None,header=True)\n",
    "        \n",
    "    else:\n",
    "        path = './broward/fairness/' + name[i] + '/six-month/property/'\n",
    "        \n",
    "        ## including arnold and compas now\n",
    "        cart_matrix = cart_summary[matrix[i]]\n",
    "        ebm_matrix = ebm_summary[matrix[i]]\n",
    "        riskslim_matrix = riskslim_cs_summary[matrix[i]]\n",
    "        stumps_matrix = stump_summary[matrix[i]]\n",
    "        arnold_matrix = arnold[matrix[i]]\n",
    "        compas_matrix = compas[matrix[i]]\n",
    "        \n",
    "        ## save results\n",
    "        cart_matrix.to_csv(path+'cart-'+name[i]+'.csv', index=None,header=True)\n",
    "        ebm_matrix.to_csv(path+'ebm-'+name[i]+'.csv', index=None,header=True)\n",
    "        riskslim_matrix.to_csv(path+'riskslim-'+name[i]+'.csv', index=None,header=True)\n",
    "        stumps_matrix.to_csv(path+'stumps-'+name[i]+'.csv', index=None,header=True)\n",
    "        arnold_matrix.to_csv(path+'arnold-'+name[i]+'.csv', index=None,header=True)\n",
    "        compas_matrix.to_csv(path+'compas-'+name[i]+'.csv', index=None,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
